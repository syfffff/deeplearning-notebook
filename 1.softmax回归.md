# 1.softmax回归

## 1.1数据集处理

```python
def get_fashion_mnist_labels(labels):  #@save
    """返回Fashion-MNIST数据集的文本标签"""
    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
    return [text_labels[int(i)] for i in labels]
```

labels为一个整型标量tensor向量每一行代表一个类别号，将labels（数字）转化为文本标签

```python
X,y=next(iter(data.DataLoader(mnist_train,batch_size=18)))
```

data.DataLoader（）：将数据集封装为一个个batch—size 大小，iter是迭代器保存了分离的n个结果，next()返回迭代器的下一个项目

```python
def load_data_fashion_mnist(batch_size, resize=None):  #@save
    """下载Fashion-MNIST数据集然后将其加载到内存中"""
    trans = [transforms.ToTensor()]
    if resize:
        trans.insert(0, transforms.Resize(resize))
    trans = transforms.Compose(trans)
    mnist_train = torchvision.datasets.FashionMNIST(
        root="../data", train=True, transform=trans, download=True)
    mnist_test = torchvision.datasets.FashionMNIST(
        root="../data", train=False, transform=trans, download=True)
    return (data.DataLoader(mnist_train, batch_size, shuffle=True,
                            num_workers=get_dataloader_workers()),
            data.DataLoader(mnist_test, batch_size, shuffle=False,
                            num_workers=get_dataloader_workers()))        
```

最终整合版本



## 1.2softmax从0开始

```python
xx=torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])
xx.sum(0,keepdim=True)   按照行进行加法运算
xx.sum(1,keepdim=True)   按着列
```

输出   tensor([[5., 7., 9.]])        [5., 7., 9.]这代表一行

输出2  tensor([[ 6.],        [15.]])      [ 6.]代表一行



```python
len（tensor）：
```

返回tensor的行数



```python
y = torch.tensor([0, 2])
y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])
y_hat[[0, 1], y]
```

y=[0,2]代表第0个样本为0类         第1个样本真的为2类

yhat=预测的 第0个样本 为0类概率0.1，为1类概率0.3 为2类概率0.6

y_hat[[0, 1], y]的意思是：取第`i`个数据正确预测的概率。如：第`0`个样本正确预测的概率是`y_hat[0,0]`即`0.1`，第`1`个样本正确预测的概率是`y_hat[1,2]`即`0.5`